syntax = "proto3";

package cuda_learning;

option go_package = "github.com/jrb/cuda-learning/proto/gen";

// Request: Go passes raw image buffer
message ProcessImageRequest {
  bytes image_data = 1 [json_name = "image_data"];      // Raw pixel data (RGBA or agreed format)
  int32 width = 3 [json_name = "width"];
  int32 height = 5 [json_name = "height"];
  int32 channels = 7 [json_name = "channels"];        // 3=RGB, 4=RGBA
  repeated FilterType filters = 9 [json_name = "filters"];  // Array of filters to apply sequentially
  AcceleratorType accelerator = 11 [json_name = "accelerator"];  // GPU or CPU processing
  GrayscaleType grayscale_type = 13 [json_name = "grayscale_type"]; // Grayscale algorithm selection
  
  // OpenTelemetry trace context propagation (deprecated - use trace_context instead)
  string trace_id = 15 [json_name = "trace_id"];      // W3C trace-id (32 hex chars)
  string span_id = 17 [json_name = "span_id"];        // W3C span-id (16 hex chars)
  uint32 trace_flags = 19 [json_name = "trace_flags"]; // W3C trace-flags (8 bit)
  
  // W3C Trace Context (unified for all layers)
  TraceContext trace_context = 21 [json_name = "trace_context"];
}

// Enum for filter types
enum FilterType {
  FILTER_TYPE_UNSPECIFIED = 0;
  FILTER_TYPE_NONE = 1;
  FILTER_TYPE_GRAYSCALE = 2;
  // Future: FILTER_TYPE_BLUR = 5, FILTER_TYPE_EDGE_DETECT = 10, etc.
}

// Enum for accelerator types
enum AcceleratorType {
  ACCELERATOR_TYPE_UNSPECIFIED = 0;
  ACCELERATOR_TYPE_GPU = 1;
  ACCELERATOR_TYPE_CPU = 2;
}

// Enum for grayscale conversion algorithms
enum GrayscaleType {
  GRAYSCALE_TYPE_UNSPECIFIED = 0;
  GRAYSCALE_TYPE_BT601 = 1;      // ITU-R BT.601 (SDTV): Y = 0.299R + 0.587G + 0.114B
  GRAYSCALE_TYPE_BT709 = 2;      // ITU-R BT.709 (HDTV): Y = 0.2126R + 0.7152G + 0.0722B
  GRAYSCALE_TYPE_AVERAGE = 3;    // Simple average: Y = (R + G + B) / 3
  GRAYSCALE_TYPE_LIGHTNESS = 4;  // Lightness: Y = (max(R,G,B) + min(R,G,B)) / 2
  GRAYSCALE_TYPE_LUMINOSITY = 5; // Luminosity: Y = 0.21R + 0.72G + 0.07B (similar to BT709)
}

// Response: C++ returns processed image buffer
message ProcessImageResponse {
  int32 code = 1 [json_name = "code"];            // 0=success, non-zero=error (gRPC style)
  string message = 3 [json_name = "message"];        // Status message or error description
  bytes image_data = 5 [json_name = "image_data"];      // Processed pixel data
  int32 width = 7 [json_name = "width"];
  int32 height = 9 [json_name = "height"];
  int32 channels = 11 [json_name = "channels"];
  TraceContext trace_context = 13 [json_name = "trace_context"];
}

// Lifecycle management
message InitRequest {
  int32 cuda_device_id = 1;  // Default 0
  TraceContext trace_context = 3 [json_name = "trace_context"];
  // Future: memory_pool_size = 5, enable_profiling = 10, etc.
}

message InitResponse {
  int32 code = 1;            // 0=success, non-zero=error
  string message = 3;        // Status or error message
  TraceContext trace_context = 5 [json_name = "trace_context"];
}

// W3C Trace Context for distributed tracing
message TraceContext {
  string traceparent = 1 [json_name = "traceparent"];
  string tracestate = 3 [json_name = "tracestate"];
}

// WebSocket stream messages
message WebSocketFrameRequest {
  string type = 1 [json_name = "type"];
  ProcessImageRequest request = 3 [json_name = "request"];
  TraceContext trace_context = 5 [json_name = "trace_context"];
}

message WebSocketFrameResponse {
  string type = 1 [json_name = "type"];
  bool success = 3 [json_name = "success"];
  string error = 5 [json_name = "error"];
  ProcessImageResponse response = 7 [json_name = "response"];
  TraceContext trace_context = 9 [json_name = "trace_context"];
}

// Stream configuration
message StreamEndpoint {
  string type = 1 [json_name = "type"];  // "websocket" or "grpc"
  string endpoint = 3 [json_name = "endpoint"];  // "/ws" or ":50051"
  string transport_format = 5 [json_name = "transport_format"];  // "json" or "binary"
}

message GetStreamConfigRequest {}

message GetStreamConfigResponse {
  repeated StreamEndpoint endpoints = 1 [json_name = "endpoints"];
}

service ImageProcessorService {
  rpc ProcessImage(ProcessImageRequest) returns (ProcessImageResponse);
  
  // TODO: Implement video streaming using Connect-RPC bidirectional streaming
  rpc StreamProcessVideo(stream ProcessImageRequest) returns (stream ProcessImageResponse);
}

service ConfigService {
  rpc GetStreamConfig(GetStreamConfigRequest) returns (GetStreamConfigResponse);
}

